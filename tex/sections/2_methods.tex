%!TEX root = ../prelims_main.tex
% \documentclass[../prelims_main.tex]{subfiles}

% \begin{document}

\section{Methods}
\begin{multicols}{2}
\subsection{Scraps}


\begin{itemize}
\item Segmenting strategies \cite{ashwoodMiceAlternateDiscrete2020}
\item Scrambled vs. unscrambled sounds? (cites 12, 18, and 25 in \cite{norman-haignereHierarchicalIntegrationMultiple2020})
\item inferring perception-action loops from data \cite{rosasCausalBlanketsTheory2020}
\item complementary roles of cell types and manifold dynamics \cite{dubreuilComplementaryRolesDimensionality2020}
\item LFADS for sequential autoencoders \cite{pandarinathInferringSingletrialNeural2018}
\item modeling auditory waveform with kernels \cite{smithEfficientAuditoryCoding2006a}
\item brain is actually a dynamic system and need to model the manifold \cite{brembsBrainDynamicallyActive2020} becasue the same brain region does multiple things at the same time with the manifold lol \cite{gallegoCorticalPopulationActivity2018}
\item ?time constant of auditory sensitivity in STG neurons?
\item The natural analog of the philosophical problem of universals in the conditioning paradigm is stimulus generalization \cite{roschWittgensteinCategorizationResearch1987}	
\item Neural nets for estimating nonlinear STRFs, se \cite{kingRecentAdvancesUnderstanding2018a}
\item extracting maximally informative features \cite{liuOptimalFeaturesAuditory2019}
\item creating superstimuli \cite{decharmsOptimizingSoundFeatures1998}
\item estimating nonlinear STRF\cite{ahrensNonlinearitiesContextualInfluences2008}
\end{itemize}

\subsection{behavior}

\draft{If the objective of the listener is to understand, ie. to be able to parse the speech sounds made by their interlocuter, then how is that different than that of the mouse, which is to get water? They are identical when water is only given when knowledge is demonstrated, but that is impossible when the chance of false positive is 50\%. more importantly how that intersects with passive learning/non-rewarded phoeme studies.}

\draft{reasons for speech stimuli: category complexity depends on the density of the space. the competition for desire for rich vocabulary of phonemes with limited articulatory palette means that we need to fit a shitload of acoustic complexity into an extremely small temporal window with a small amount of potential variation. So yeah parameterized mouse calls might work but that's like a feature of the density of the communication space, but they also have extremely subtle cues in their environment that they need to parse... so speech sounds are good because they're not species-specific but also because they're stimuli that we know have a potential subjective categorization structure but one that is sufficiently complex. speech sounds also take advantage of the innate contours of the auditory system, }

\draft{trying a fresh rewrite: q: why use natural speech rather than some other synthesized, complex, high-dimensional acoustic stimulus?
a: though the question is about auditory category learning in general, the auditory system is not some lockean tabula rasa because natural law dictates that auditory reality isn’t some equiprobable playground where all sounds are possible. the auditory system evolved to be better able to learn certain acoustic contrasts compared to others because the fact that some contrasts are more informative than others is written into the very sinew of natural law (cite patricia kuhl’s ‘basic cuts’ argument, tony zador ‘critique of pure learning’). it is also not sufficient to identify one or a few of these ‘natural auditory-perceptual gradients’ and synthesize stimuli along them: the problem that languages have been solving for <many> years is how to pack many contrasts that are all mutually intelligible at rapid timescales (low … resolution?) across those gradients. Close phonetic contrasts are thus complex stimuli optimized to be discriminable by the mammalian auditory system in a dense category-space, making the reliance on the family resemblance-type structure (rather than a simple rule-based solution) that typifies phonetic identification and other complex category processing necessary}


\subsection{imaging}

\subsection{analysis \& modeling}

\idea{Start with demonstration from tensorflow.js playground that learns a simple 2-d nonlinearity by becoming sensitive to the product of the two `base' dimensions. it's a projection to a geometry that allows them to be discriminable. that's the basic idea.}


If $P$ is discrete, and the process of assigning category is feature comparison, we get tversky - talk about how not inferring stimulus parameters is important re: \cite{krantzSimilarityRectanglesAnalysis1975a,tverskyStudiesSimilarity1978,Tversky1970} contrast hierarchy <-> tversky's trees in features of similarity, tversky's objections can also be re-expressed as a crit of shitty geometry, rather than abandoning geometry, we need to estimate a geometry that does operate metrically (even if the dimensions operate categorically rather than continuously) (though he does consider weights here \cite{ritovDifferentialWeightingCommon1990})

The history of this question includes Shepard and Tversky's multidimensional scaling and its criticisms, and also extends through Shepherds' "second-order isomorphisms" (cite representation is representation of similarity)


Neuroscientists sorta blithely assume what the features of a stimulus are, from the seemingly harmless and physically based -- frequency, direction, angle, etc. -- to the absurd -- rsa et al. But these dimensions rarely behave like `real' perceptual dimensions \cite{krantzSimilarityRectanglesAnalysis1975a} -- the transformation is actually the critical part. 

assuming feature dimensions is always a bad assumption -- eg what features have the metric structure that measure similarity/dissimilarity of rectangles? \cite{krantzSimilarityRectanglesAnalysis1975a}

\end{multicols}
% \end{document}